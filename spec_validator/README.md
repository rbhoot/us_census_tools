# Spec Validator

## Description

The validator tool tries to do basic sanity checks on the spec.

The script parses:
- The set of CSV files downloaded from census (Any one)
	- List of CSV file paths
	- List of ZIP file paths
	- JSON file containing list of all columns
- Config Spec JSON file

It tries to identify:
- Tokens appearing in spec but not in any of the CSV files
- Tokens appearing in CSV files but not in spec
- Columns that have no property assignment
- Columns that might possibly be in conflict with ignore and property assignment
- Missing Denominator Total Columns
- Denominator ccolumn appearing under multiple totals
- Possible missing EnumSpecialisations
- Multiple measurement assignment
- Multiple population assignment
- Extra inferredSpec

And creates:
- List and count of all column names
- List and count of all ignored column names
- List and count of all accepted column names

The script generates column and token data file and another file with outcome of results in the output directory

`all` key of dictionary refers to combination across all the files in the input

filename based outcomes can also be found in the output files

`filewise` option is generally used for debug purposes only

`check_metadata` for zip file, `is_metadata` for CSV files can be made True if _metadata_ type files need to be processed

## Commandline options
- `spec_path` - path to JSON file containing the spec
- `column_list_path` - path of JSON file containing a list of all columns, present in https://github.com/rbhoot/acs_tables
- `zip_list` - Comma seperated list of paths of zip files fetched from census
- `csv_list` - Comma seperated list of paths of csv files fetched from census
- `tests` - Can take multiple values from:
	- all
	- extra_tokens
	- missing_tokens
	- column_no_pv
	- ignore_conflicts
	- enum_specialisations
	- denominators
	- extra_inferred
	- multiple_measurement
	- multiple_population
- `validator_output` - The output directory for the files generated by the validator. The files generated include:
	- `test_results.json` - Contains output of each test.
	- `columns.json` - Contains the list of columns by year and combined, also has seperate section for ignored columns.

## Commandline invocation examples

To run all tests against zip file:
```
python acs_spec_validator.py --zip_list=~/acs_tables/S0701/S0701_us.zip --spec_path=../spec_dir/S0701_spec.json --validator_output=~/acs_tables/S0701/validator
```
To run all tests against list of columns:
```
python acs_spec_validator.py --column_list_path=~/acs_tables/S0701/all_columns.json --spec_path=../spec_dir/S0701_spec.json --validator_output=~/acs_tables/S0701/validator
```

# Column map validator

## Description

The validator checks the column map generated from `process.py` or `generate_col_map.py`.

Following checks are performed on the column map:
- Presence of extra columns that should have been ignored
- Absence of columns that should not have been ignored
- Count of StatVars of type MarginOfError and not MarginOfError
- Presence of StatVar that has only margin of error
- Different StatVars having same DCID
- Same StatVar being generated multiple times in the same year
- DCID time series holes
- DCIDs unique to particular year
- DCIDs missing in particular year

## Commandline options

- `spec_path` - path to JSON file containing the spec
- `column_map` - path to JSON file containing the column map generated by processing script
- `yearwise_columns` - path of JSON file containing a list of all columns grouped by year, present in https://github.com/rbhoot/acs_tables
- `colmap_validation_output` - path of the directory to write output files 

## Commandline invocation examples
```
python column_map_validator.py --spec_path=../spec_dir/S0701_spec.json --column_map=~/acs_tables/S0701/column_map.json --yearwise_columns=~/acs_tables/S0701/yearwise_columns.json --colmap_validation_output=~/acs_tables/S0701/
```